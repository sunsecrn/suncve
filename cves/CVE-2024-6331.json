{"cveId": "CVE-2024-6331", "cwe": ["CWE-74", "CWE-74", "CWE-74", "CWE-74", "CWE-74"], "cvss": [{"baseScore": "7.5", "version": "3.1", "Attack Vector": "None", "Attack Complexity": "Low", "Privileges Required": "None", "User Interaction": "None", "Scope": "Unchaged", "Confidentiality Impact": "High", "Integrity Impact": "None", "Availability Impact": "None"}], "references": ["https://huntr.com/bounties/d5ac1051-22fa-42f0-8d82-73267482e60f"], "description": ["stitionai/devika main branch as of commit cdfb782b0e634b773b10963c8034dc9207ba1f9f is vulnerable to Local File Read (LFI) by Prompt Injection. The integration of Google Gimini 1.0 Pro with `HarmBlockThreshold.BLOCK_NONE` for `HarmCategory.HARM_CATEGORY_HATE_SPEECH` and `HarmCategory.HARM_CATEGORY_HARASSMENT` in `safety_settings` disables content protection. This allows malicious commands to be executed, such as reading sensitive file contents like `/etc/passwd`."], "published": "2024-08-04T00:15:47.863", "state": "PUBLIC", "vendorName": ["stitionai"], "productName": ["stitionai/devika"], "github": {"advisories": [], "commits": [], "pocAdvisorie": null, "repo": null, "info": {}}, "pocList": []}